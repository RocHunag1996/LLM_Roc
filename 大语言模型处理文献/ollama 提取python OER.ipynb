{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文献: 100%|██████████| 973/973 [15:54<00:00,  1.02篇/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文献分析已完成，结果已保存到 OER_ollama文献分析结果.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import ollama   \n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # 导入进度条库\n",
    "\n",
    "# 调用 Ollama 模型进行分析\n",
    "def analyze_abstract_with_ollama(prompt):\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.2:latest\",\n",
    "        stream=False,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "    if \"message\" in response and \"content\" in response[\"message\"]:\n",
    "        return response[\"message\"][\"content\"]  # 返回有效内容\n",
    "    else:\n",
    "        return \"未返回有效内容\"\n",
    "\n",
    "# 生成提示词\n",
    "def generate_prompt(abstract):\n",
    "    prompt = f\"\"\"\n",
    "    You are a research assistant specialized in analyzing scientific papers related to high-entropy materials and their application in hydrogen evolution reaction (HER) catalysis.\n",
    "    Your task is to extract the following specific information from the research article abstract provided below:\n",
    "\n",
    "    1. Article Type: Determine whether this is a research article or a review article.\n",
    "    2. identify if it discusses relevant to OER catalysis.\n",
    "    3. list the elements used (e.g., Co, Ni, Fe) specifically for catalysis.\n",
    "    \n",
    "    Provide only the requested information, keeping the response concise and clear.\n",
    "\n",
    "    Abstract: {abstract}\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "# 解析分析结果的函数\n",
    "def parse_analysis_result(analysis_result, is_research, is_high_entropy):\n",
    "    return {\"Model_Response\": analysis_result} if is_research and is_high_entropy else {\"Model_Response\": analysis_result}\n",
    "\n",
    "# 处理文献\n",
    "def process_documents(documents):\n",
    "    results = []\n",
    "    for doc in tqdm(documents, desc=\"处理文献\", unit=\"篇\"):  # 显示进度条\n",
    "        prompt = generate_prompt(doc[\"Abstract\"])  # 生成提示词\n",
    "        analysis_result = analyze_abstract_with_ollama(prompt)  # 调用模型分析\n",
    "        \n",
    "        # 解析返回的结果并判断类型\n",
    "        is_research = \"research article\" in analysis_result.lower()  # 判断是否为研究性文章\n",
    "        is_high_entropy = \"high-entropy\" in analysis_result.lower()  # 判断是否涉及高熵材料\n",
    "        parsed_result = parse_analysis_result(analysis_result, is_research, is_high_entropy)  # 解析结果\n",
    "        \n",
    "        results.append({\n",
    "            \"标题\": doc[\"Article Title\"],  # 添加标题\n",
    "            \"摘要\": doc[\"Abstract\"],  # 添加摘要  \n",
    "            \"模型响应\": parsed_result[\"Model_Response\"]  # 添加模型响应\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# 保存结果到 CSV 文件\n",
    "def save_results_to_csv(results, output_file):\n",
    "    df = pd.DataFrame(results)  # 将结果转换为 DataFrame\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8-sig')  # 保存为 CSV 文件，支持中文字符\n",
    "\n",
    "# 读取文献文件（假设文献格式为 XLS 文件）\n",
    "def read_documents(file_path):\n",
    "    df = pd.read_excel(file_path)  # 读取 XLS 文件\n",
    "    documents = df[['Article Title', 'Abstract']].to_dict(orient='records')  # 获取指定列\n",
    "    return documents\n",
    "\n",
    "# 主流程\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = 'OER.xls'  # 输入文件名\n",
    "    documents = read_documents(input_file)  # 读取文献\n",
    "    results = process_documents(documents)  # 处理文献\n",
    "    \n",
    "    # 生成输出文件名\n",
    "    output_file = f\"{input_file.split('.')[0]}_ollama文献分析结果.csv\"  \n",
    "    save_results_to_csv(results, output_file)  # 保存结果到 CSV 文件\n",
    "\n",
    "    print(f\"文献分析已完成，结果已保存到 {output_file}\")  # 输出完成信息\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 75\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# 主流程\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 75\u001b[0m     documents \u001b[38;5;241m=\u001b[39m \u001b[43mread_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOER.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 读取文献\u001b[39;00m\n\u001b[0;32m     76\u001b[0m     results \u001b[38;5;241m=\u001b[39m process_documents(documents)  \u001b[38;5;66;03m# 处理文献\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     save_results_to_csv(results, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHER_ollama文献分析结果.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 保存结果到 CSV 文件\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[19], line 69\u001b[0m, in \u001b[0;36mread_documents\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     67\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(file, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 使用制表符分隔\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n\u001b[1;32m---> 69\u001b[0m         title, abstract \u001b[38;5;241m=\u001b[39m row  \u001b[38;5;66;03m# 获取标题和摘要\u001b[39;00m\n\u001b[0;32m     70\u001b[0m         documents\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: title, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabstract\u001b[39m\u001b[38;5;124m\"\u001b[39m: abstract})  \u001b[38;5;66;03m# 添加到文献列表\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m documents\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "#输入是txt文本\n",
    "\n",
    "import ollama  \n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # 导入进度条库\n",
    "\n",
    "# 调用 Ollama 模型进行分析\n",
    "def analyze_abstract_with_ollama(prompt):\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.2:latest\",\n",
    "        stream=False,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        options={\"temperature\": 0}\n",
    "    )\n",
    "    if \"message\" in response and \"content\" in response[\"message\"]:\n",
    "        return response[\"message\"][\"content\"]  # 返回有效内容\n",
    "    else:\n",
    "        return \"未返回有效内容\"\n",
    "\n",
    "# 生成提示词\n",
    "def generate_prompt(abstract):\n",
    "    prompt = f\"\"\"\n",
    "    You are a research assistant specialized in analyzing scientific papers related to high-entropy materials and their application in hydrogen evolution reaction (HER) catalysis.\n",
    "    Your task is to extract the following specific information from the research article abstract provided below:\n",
    "\n",
    "    1. Article Type: Determine whether this is a research article or a review article.\n",
    "    2. identify if it discusses relevant to OER catalysis.\n",
    "    3. list the high-entropy elements used (e.g., Co, Ni, Fe) specifically for catalysis.\n",
    "    \n",
    "    Provide only the requested information, keeping the response concise and clear.\n",
    "\n",
    "    Abstract: {abstract}\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "# 解析分析结果的函数\n",
    "def parse_analysis_result(analysis_result, is_research, is_high_entropy):\n",
    "    return {\"Model_Response\": analysis_result} if is_research and is_high_entropy else {\"Model_Response\": analysis_result}\n",
    "\n",
    "# 处理文献\n",
    "def process_documents(documents):\n",
    "    results = []\n",
    "    for doc in tqdm(documents, desc=\"处理文献\", unit=\"篇\"):  # 显示进度条\n",
    "        prompt = generate_prompt(doc[\"abstract\"])  # 生成提示词\n",
    "        analysis_result = analyze_abstract_with_ollama(prompt)  # 调用模型分析\n",
    "        \n",
    "        # 解析返回的结果并判断类型\n",
    "        is_research = \"research article\" in analysis_result.lower()  # 判断是否为研究性文章\n",
    "        is_high_entropy = \"high-entropy\" in analysis_result.lower()  # 判断是否涉及高熵材料\n",
    "        parsed_result = parse_analysis_result(analysis_result, is_research, is_high_entropy)  # 解析结果\n",
    "        \n",
    "        results.append({\n",
    "            \"标题\": doc[\"title\"],  # 添加标题\n",
    "            \"摘要\": doc[\"abstract\"],  # 添加摘要  \n",
    "            \"模型响应\": parsed_result[\"Model_Response\"]  # 添加模型响应\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# 保存结果到 CSV 文件\n",
    "def save_results_to_csv(results, output_file):\n",
    "    df = pd.DataFrame(results)  # 将结果转换为 DataFrame\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8-sig')  # 保存为 CSV 文件，支持中文字符\n",
    "\n",
    "# 读取文献文件（假设文献格式为 \"标题\\t摘要\"）\n",
    "def read_documents(file_path):\n",
    "    documents = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')  # 使用制表符分隔\n",
    "        for row in reader:\n",
    "            title, abstract = row  # 获取标题和摘要\n",
    "            documents.append({\"title\": title, \"abstract\": abstract})  # 添加到文献列表\n",
    "    return documents\n",
    "\n",
    "# 主流程\n",
    "if __name__ == \"__main__\":\n",
    "    documents = read_documents('OER.txt')  # 读取文献\n",
    "    results = process_documents(documents)  # 处理文献\n",
    "    save_results_to_csv(results, 'HER_ollama文献分析结果.csv')  # 保存结果到 CSV 文件\n",
    "\n",
    "    print(\"文献分析已完成，结果已保存到 OER_ollama文献分析结果.csv\")  # 输出完成信息\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
